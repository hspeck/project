{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thinking the next step through\n",
    "\n",
    "Based on the tree of whirlin we made (best top 3 hits), it seems clear that some of the taxa investigated do not have the gene\n",
    "\n",
    "either they have lost it, or never had it in the first place (either are interesting results!)\n",
    "\n",
    "Because Whirlin, Harmonin, and PDZD7 are highly similar, it seems further likely that if there was no good result for Whirlin, (e.g. C. elegans got MAGI instead of harmonin) it seems likely that there are no good results for the other two genes\n",
    "\n",
    "Let's investigate the branching nature of ht gnes a bit further\n",
    "\n",
    "    for the species which clustered with human whirlin, or have xplicitly called harmoin/whirlin as seen in the tree\n",
    "Also let's put Lingula back in the tree, it should really be there\n",
    "\n",
    "    We will take the best hit from each of the genes (Whirlin, harmonin, PDZD7)\n",
    "\n",
    "        we will concatenate gene ID's into a single file which will not have any redundancies in it\n",
    "\n",
    "    Download the genes from NCBI (may want to download the Gi format, so can get CDD annotation out of it)\n",
    "\n",
    "        Can also download in FASTA format to trouble shoot a bit\n",
    "\n",
    "    Muscle align them\n",
    "\n",
    "    RAxML it\n",
    "\n",
    "    check the results in R studio\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Spend a bit of time to make sure we can reliably retrieve the id's and names\n",
    "\n",
    "Below is giving us the full list of orgs of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'close'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-11e102b0bf70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mformated_list_taxaID\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_line\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mformated_list_taxaID\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtaxa_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'close'"
     ]
    }
   ],
   "source": [
    "taxa_list = open(\"list_of_org_IDs_long.csv\", \"r\").readlines()\n",
    "taxa_ID_numbers=[]\n",
    "taxa_names=[]\n",
    "\n",
    "formated_list_taxaID = open(\"taxa_list_full_formated.txt\", \"w\")\n",
    "#sets the holder names\n",
    "for line in taxa_list:\n",
    "    taxa_ID_number = line.split(\":\")[1].replace(\")\\n\", \"\")  #gets us only the numbers in a nice little list\n",
    "    taxa_name = line.split(\"(\")[0][:-1].replace(\" \", \"_\") #gets us just the genus and species name\n",
    "    output_line = taxa_name + \",\" + taxa_ID_number +\"\\n\" #set's the output line\n",
    "    formated_list_taxaID.write(output_line)\n",
    "formated_list_taxaID.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting just our test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "taxa_list = open(\"list_of_org_IDs.csv\", \"r\").readlines()\n",
    "taxa_ID_numbers=[]\n",
    "taxa_names=[]\n",
    "\n",
    "formated_list_taxaID = open(\"taxa_list_test_formated.txt\", \"w\")\n",
    "#sets the holder names\n",
    "for line in taxa_list:\n",
    "    taxa_ID_number = line.split(\":\")[1].replace('\"', '').replace(\"\\n\", \"\")  \n",
    "    #gets us only the numbers in a nice little list\n",
    "    taxa_name = line.split('\\t')[0].replace(\" \", \"_\") #gets us just the genus and species name\n",
    "    output_line = taxa_name + \",\" + taxa_ID_number +\"\\n\" #set's the output line\n",
    "    formated_list_taxaID.write(output_line)\n",
    "formated_list_taxaID.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now just getting the orgs of interest that showed something from the tree exercise and the annotation, as well as a few more taxa to get some resolution in the tree at some of the nodes\n",
    "\n",
    "Homo\n",
    "\n",
    "Strongylocentrotus\n",
    "\n",
    "Nematostella\n",
    "\n",
    "Hydra\n",
    "\n",
    "Drosophila\n",
    "\n",
    "Salpingoeca\n",
    "\n",
    "Octopus\n",
    "\n",
    "Amphimedon\n",
    "\n",
    "We'll add back in Lingula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grabbing the gene id's of interest\n",
    "\n",
    "### for the full list of taxa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_and_getID_best_hits(taxa_id_list, file_format_name):\n",
    "    #  goes through the output of a BLAST xml file \n",
    "    #  finds the best result for the taxa's submited\n",
    "    from Bio.Blast import NCBIXML\n",
    "    from Bio.SeqRecord import SeqRecord\n",
    "    #import the required libraries\n",
    "    \n",
    "    for taxa_id in taxa_id_list:\n",
    "        file_name = str(\"USH_Search_\" + \"txid\" +taxa_id + \"[ORGN].xml\")\n",
    "        #this sets the handle, without having to format every single name of the input files\n",
    "        #added a txid, so we only need to grab only the number from the file, nothing else\n",
    "        \n",
    "        result_handle = open(str(\"/home/eeb177-student/Desktop/eeb-177/project/sandbox/Testrun_multi_genes_same_org/Batch_run_workspace/\"+file_name), \"r\") #sets the result handle to read the results from\n",
    "        #i've altered this to be able to find the genes without having them in the same directory\n",
    "        \n",
    "        blast_records = NCBIXML.parse(result_handle)\n",
    "        #need to use parse if it has multiple records in it\n",
    "        for blast_record in blast_records:\n",
    "            org_desig=file_name.split(\"_\")[2].split(\"[\")[0].replace(\" \", \"_\")\n",
    "            #properly formats the taxa id so we can use it to name things\n",
    "            \n",
    "            homo_sapiens = \"[Homo sapiens]\"\n",
    "            blast_query=blast_record.query\n",
    "            if homo_sapiens in blast_query:\n",
    "                gene_name=blast_record.query.split(\"|\")[4].split(\"[\")[0].replace(\" \", \"_\").replace(\"_protein\", \"\").replace(\"_isoform_b3\", \"\")\n",
    "                formated_gene_name = gene_name[1:-1]\n",
    "            else:\n",
    "                formated_gene_name=blast_query.split(\"|\")[4].split(\"_\")[0]\n",
    "            #this conditional properly formats the gene name so we can use it to name things\n",
    "                #Basically there are 2 formats of sequence names I used to do the search\n",
    "                #this statement switches the naming convention depending on which is used\n",
    "                #it's not very general, so in the future I will make sure to properly name my search sequences\n",
    "                #that should make this statement unnecessary \n",
    "            \n",
    "            \n",
    "            output_file_name=(\"gene_\"+formated_gene_name +\"_\"+file_format_name+ \"_summary.csv\")\n",
    "            #changed this line so we can add the extra variable so we don't have to redefine the function every time we run it\n",
    "        \n",
    "            output_file=open(output_file_name, \"a\")\n",
    "            \n",
    "            #this puts together a nicely named file for each gene and species\n",
    "            \n",
    "            alignment_file_contents=\"\"\n",
    "            #setting up an empty list to hold the output of the following loop\n",
    "            for alignment in blast_record.alignments[:1]:\n",
    "                #change the number here to determine how many of the hits you the number specifies \n",
    "                #if it is 3 that you are grabing the 3 best hits\n",
    "\n",
    "                score_counter=[]\n",
    "                e_val_counter=[]\n",
    "\n",
    "                for hsp in alignment.hsps:\n",
    "                    evalue=hsp.expect\n",
    "                    e_val_counter.append(evalue)\n",
    "                \n",
    "                seq_designation = alignment.title.split(\"|\")\n",
    "                gi_number = seq_designation[1]\n",
    "                ref_number = seq_designation[3]\n",
    "                annotation = seq_designation[4]\n",
    "                #breaking apart the annoation of the sequence name\n",
    "                #otherwise we'd have way too many delimiters within delimiters\n",
    "                output_line = str(gi_number + \",\"+ \n",
    "                                  ref_number + \",\" +\n",
    "                                  annotation+ \",\" +\n",
    "                                  str(min(e_val_counter)) + \"\\n\")\n",
    "                #this sets up the output for each alignment\n",
    "                #had to alter the line breaks and parenthesis positioning\n",
    "                \n",
    "                alignment_file_contents = alignment_file_contents + output_line\n",
    "                #this writes what we came up with to the holder string\n",
    "            output_file.write(alignment_file_contents)\n",
    "            #writing the output to the alignment file\n",
    "            output_file.close()\n",
    "        result_handle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### Now lets read in the list of IDs and get them running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_list_taxa_file = open(\"taxa_list_full_formated.txt\", \"r\").readlines()\n",
    "full_taxa_list = [] #set up a holder to append into\n",
    "for line in full_list_taxa_file:\n",
    "    full_taxa_list.append(line.split(\",\")[1].strip(\"\\n\")) #get the ids only\n",
    "    \n",
    "\n",
    "test_list_taxa_file = open(\"taxa_list_test_formated.txt\",\"r\").readlines()\n",
    "test_taxa_list = [] #set up a holder to append into\n",
    "for line in test_list_taxa_file:\n",
    "    test_taxa_list.append(line.split(\",\")[1].strip(\"\\n\")) #get the ids only\n",
    "\n",
    "harm_fam_list_taxa_file = open(\"taxa_list_WHRN_Harm_PDZD7_formated.txt\", \"r\").readlines()\n",
    "harm_fam_taxa_list = [] #set up a holder to append into\n",
    "for line in harm_fam_list_taxa_file:\n",
    "    harm_fam_taxa_list.append(line.split(\",\")[1].strip(\"\\n\")) #get the ids only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['946362', '400682', '9606', '45351', '6087', '7668', '7227', '37653', '7574']\n",
      "['2850', '55529', '164328', '5888', '5833', '1202447', '505693', '227086', '46433', '5691', '55529', '5762', '2769', '3702', '3067', '361139', '44689', '5759', '281847', '691883', '109871', '6035', '4837', '4932', '5011', '203908', '588596', '28583', '73868', '34488', '61392', '192875', '134558', '72019', '81824', '946362', '9606', '400682', '7227', '529818', '10228', '45351', '6087', '669202', '7719', '7955', '10090', '10224', '7668', '37621', '6239', '6334', '6945', '60516', '6185', '79327', '7574', '225164', '37653', '6412']\n",
      "['81824', '44689', '946362', '529818', '192875', '10228', '400682', '9606', '45351', '6087', '7668', '6239', '7227', '37653', '7574']\n"
     ]
    }
   ],
   "source": [
    "print(harm_fam_taxa_list)\n",
    "print(full_taxa_list)\n",
    "print(test_taxa_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parse_and_getID_best_hits(harm_fam_taxa_list, \"WHRN_harm_PDZD7_treebuilding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we switch to the shell for a bit\n",
    "```\n",
    "cat gene_PDZD7_WHRN_harm_PDZD7_treebuilding_summary.csv >> WHRN_harm_PDZD7_summary.csv\n",
    "\n",
    "cat gene_WHRN_WHRN_harm_PDZD7_treebuilding_summary.csv >> WHRN_harm_PDZD7_summary.csv \n",
    "\n",
    "cat gene_harmonin_WHRN_harm_PDZD7_treebuilding_summary.csv >> WHRN_harm_PDZD7_summary.csv \n",
    "```\n",
    "Need to use the gene ID name, otherwise the different e-values will make them register as different lines\n",
    "```\n",
    "cat WHRN_harm_PDZD7_summary.csv | cut -d \",\"  -f 1 | sort | uniq > WHRN_harm_PDZD7_gi.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Now to download the sequences from NCBI in the file WHRN_harm_PDZD7_gene_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_seqs_from_list_and_autoname(in_filename):    \n",
    "    with open(in_filename, \"r\") as query_file:\n",
    "        query_ids = query_file.read().splitlines()\n",
    "    #open the file, grab the ids\n",
    "\n",
    "    from Bio import Entrez\n",
    "    Entrez.email = \"hspeck@ucla.edu\"\n",
    "    # import Bio Entrez, let NCBI know who I am\n",
    "\n",
    "    search_results = Entrez.read(Entrez.epost(db =\"protein\", \n",
    "                                              id = \",\".join(query_ids)))  # needs the id's to be as a list separated by commas\n",
    "    #upload the IDs to NCBI\n",
    "    webenv_return = search_results[\"WebEnv\"]\n",
    "    query_key_return = search_results[\"QueryKey\"]\n",
    "    #grab the relevant variables to call on the stuff we posted\n",
    "\n",
    "    count = len(query_ids)\n",
    "    #assigns the count based on the number of sequences we searched for\n",
    "\n",
    "    from urllib.error import HTTPError\n",
    "    # load required library for the try and except conditions\n",
    "\n",
    "    batch_size = 20\n",
    "    #this determines how many things we retrieve and write to the file\n",
    "    #can safely be larger in the future\n",
    "\n",
    "    out_filename = str(in_filename[:-7]+\".fasta\")\n",
    "    #attempting to rename the file based on the input of the original file\n",
    "    out_handle = open(out_filename, \"w\")\n",
    "    #open file to write to\n",
    "\n",
    "    for start in range(0, count, batch_size):\n",
    "        end = min(count, start+batch_size)\n",
    "        print(\"Going to download record %i to %i\" % (start+1, end))\n",
    "        attempt = 0\n",
    "        while attempt < 3:\n",
    "            attempt += 1\n",
    "            try:\n",
    "                fetch_handle = Entrez.efetch(db=\"protein\", #says which db\n",
    "                                             rettype=\"fasta\", #says what format the data should be in\n",
    "                                             retmode=\"text\", #what the output should be\n",
    "                                             retstart = start, #say what range of results you want returned\n",
    "                                             retmax = batch_size, #say end of range of results want returned\n",
    "                                             webenv = webenv_return, #specify the info we uploaded with ePost\n",
    "                                             query_key = query_key_return)\n",
    "            except HTTPError as err:\n",
    "                if 500 <= err.code <= 599:\n",
    "                    print(\"Recieved error from server %s\" % err)\n",
    "                    print(\"Attempt %i of 3\" % attempt)\n",
    "                    time.sleep\n",
    "                else:\n",
    "                    raise\n",
    "        data = fetch_handle.read()\n",
    "        fetch_handle.close()\n",
    "        out_handle.write(data)\n",
    "    out_handle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to download record 1 to 20\n"
     ]
    }
   ],
   "source": [
    "download_seqs_from_list_and_autoname(\"WHRN_harm_PDZD7_gi.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Bio.Align.Applications import MuscleCommandline\n",
    "muscle_cline = MuscleCommandline(input = \"WHRN_harm_PDZD7.fasta\", \n",
    "                                 out = \"WHRN_harm_PDZD7_MUSCLE_align.txt\")\n",
    "stdout, stder = muscle_cline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
