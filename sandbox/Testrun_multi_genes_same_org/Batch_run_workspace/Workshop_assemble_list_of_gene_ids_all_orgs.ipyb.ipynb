{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with current system (i.e. a for every gene-org combo) can pull up all results for a single gene with\n",
    "```\n",
    "cat *myosin_VIIA_summary.csv\n",
    "```\n",
    "can then pass it to\n",
    "```\n",
    "|cut -d \",\" -f 1 | cut -d \":\" -f 2  > entrez_test_mult_queries.txt\n",
    "```\n",
    "this should be a full list of everything for that gene,\n",
    "can name the file better later\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us more than we had, and it seems like it worked fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Question is, do we want to make a better way of parsing the results?\n",
    "\n",
    "yes, probably\n",
    "\n",
    "THinking about modifying our current function of parsing loop to create the file name and open it automatically\n",
    "but how to not overwrite it?\n",
    "\n",
    "when you open the file\n",
    "use \"a\", this will append to the file\n",
    "not \"w\", this will overwrite the file as it is written to repeatedly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Altering the parse and summarize file to separate out the sequences by gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_and_summarize(blast_output_xml):\n",
    "    #  goes through the output of a BLAST xml file and finds the relevant stats to summarize the search\n",
    "    from Bio.Blast import NCBIXML\n",
    "    from Bio.SeqRecord import SeqRecord\n",
    "    #import the required libraries\n",
    "    \n",
    "    for file_name in blast_output_xml:\n",
    "        result_handle = open(str(file_name), \"r\") #sets the result handle\n",
    "        blast_records = NCBIXML.parse(result_handle)\n",
    "        #need to use parse if it has multiple records in it\n",
    "        for blast_record in blast_records:\n",
    "            org_desig=file_name.split(\"_\")[2].split(\"[\")[0].replace(\" \", \"_\")\n",
    "            #properly formats the taxa id so we can use it to name things\n",
    "            \n",
    "            homo_sapiens = \"[Homo sapiens]\"\n",
    "            blast_query=blast_record.query\n",
    "            if homo_sapiens in blast_query:\n",
    "                gene_name=blast_record.query.split(\"|\")[4].split(\"[\")[0].replace(\" \", \"_\").replace(\"_protein\", \"\").replace(\"_isoform_b3\", \"\")\n",
    "                formated_gene_name = gene_name[1:-1]\n",
    "            else:\n",
    "                formated_gene_name=blast_query.split(\"|\")[4].split(\"_\")[0]\n",
    "            #this conditional properly formats the gene name so we can use it to name things\n",
    "                #Basically there are 2 formats of sequence names I used to do the search\n",
    "                #this statement switches the naming convention depending on which is used\n",
    "                #it's not very general, so in the future I will make sure to properly name my search sequences\n",
    "                #that should make this statement unnecessary \n",
    "            \n",
    "            \n",
    "            output_file_name=(formated_gene_name + \"_summary.csv\")    \n",
    "            output_file=open(output_file_name, \"a\")\n",
    "            #this puts together a nicely named file for each gene and species\n",
    "            \n",
    "            alignment_file_contents=\"\"\n",
    "            #setting up an empty list to hold the output of the following loop\n",
    "            for alignment in blast_record.alignments:\n",
    "\n",
    "                score_counter=[]\n",
    "                e_val_counter=[]\n",
    "\n",
    "                for hsp in alignment.hsps:\n",
    "                    score=hsp.score\n",
    "                    score_counter.append(score)\n",
    "                    evalue=hsp.expect\n",
    "                    e_val_counter.append(evalue)\n",
    "                \n",
    "                seq_designation = alignment.title.split(\"|\")\n",
    "                gi_number = seq_designation[1]\n",
    "                ref_number = seq_designation[3]\n",
    "                annotation = seq_designation[4]\n",
    "                #breaking apart the annoation of the sequence name\n",
    "                #otherwise we'd have way too many delimiters within delimiters\n",
    "                output_line = str(\"gi:\" + gi_number + \",\"+\n",
    "                                 \"ref_number:\" + ref_number + \",\" +\n",
    "                                 \"annotation:\" + annotation+ \",\" +\n",
    "                                \"best_score:\"+ str(max(score_counter)) + \",\"+\n",
    "                                \"evalue:\" + str(min(e_val_counter)) + \",\"\n",
    "                                \"length:\" + str(alignment.length)+\"\\n\")\n",
    "                #this sets up the output for each alignment\n",
    "                \n",
    "                alignment_file_contents = alignment_file_contents + output_line\n",
    "                #this writes what we came up with to the holder string\n",
    "            \n",
    "            output_file.write(alignment_file_contents)\n",
    "            #writing the output to the alignment file\n",
    "            output_file.close()\n",
    "\n",
    "        result_handle.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_blast_xml = [\"USH_Search_txid45351[ORGN].xml\", \"USH_Search_txid400682[ORGN].xml\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parse_and_summarize(list_of_blast_xml)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Well that was much less of a problem than I thought it would be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only real problem comes with the issue of needing to delete these guys when I want to rerun it with a larger data set.\n",
    "ultimately pretty minor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Let's use bash to get us a list of all the Blast docs!\n",
    "\n",
    "I think a few of the BLAST results may have gone missing?\n",
    "bash says we have 59\n",
    "from list of orgs to search should have 61?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Let's find out! \n",
    "\n",
    "#Can do this later I say werid formatting things will come up and I will get tired\n",
    "\n",
    "\n",
    "full_taxa_file_name=open(\"/home/eeb177-student/Desktop/eeb-177/project/sandbox/Testrun_multi_genes_same_org/full_list_taxa_NCBI.txt\", \"r\")\n",
    "full_taxa_list= full_taxa_file_name.readlines()\n",
    "full_taxa_list\n",
    "\n",
    "#basically want to create a logical comparison for elements in one vector within other vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just run it for the taxa we can extract from Bash easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_List_of_Blast_XMLs = open(\"/home/eeb177-student/Desktop/eeb-177/project/sandbox/Testrun_multi_genes_same_org/Batch_run_workspace/list_of_BLAST_XML.txt\", \"r\")\n",
    "list_of_BLAST_XMLs = file_List_of_Blast_XMLs.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['USH_Search_txid10090[ORGN].xml',\n",
       " 'USH_Search_txid10224[ORGN].xml',\n",
       " 'USH_Search_txid10228[ORGN].xml',\n",
       " 'USH_Search_txid109871[ORGN].xml',\n",
       " 'USH_Search_txid1202447[ORGN].xml',\n",
       " 'USH_Search_txid134558[ORGN].xml',\n",
       " 'USH_Search_txid164328[ORGN].xml',\n",
       " 'USH_Search_txid192875[ORGN].xml',\n",
       " 'USH_Search_txid203908[ORGN].xml',\n",
       " 'USH_Search_txid225164[ORGN].xml',\n",
       " 'USH_Search_txid227086[ORGN].xml',\n",
       " 'USH_Search_txid2769[ORGN].xml',\n",
       " 'USH_Search_txid281847[ORGN].xml',\n",
       " 'USH_Search_txid2850[ORGN].xml',\n",
       " 'USH_Search_txid28583[ORGN].xml',\n",
       " 'USH_Search_txid3067[ORGN].xml',\n",
       " 'USH_Search_txid34488[ORGN].xml',\n",
       " 'USH_Search_txid361139[ORGN].xml',\n",
       " 'USH_Search_txid3702[ORGN].xml',\n",
       " 'USH_Search_txid37621[ORGN].xml',\n",
       " 'USH_Search_txid37653[ORGN].xml',\n",
       " 'USH_Search_txid400682[ORGN].xml',\n",
       " 'USH_Search_txid44689[ORGN].xml',\n",
       " 'USH_Search_txid45351[ORGN].xml',\n",
       " 'USH_Search_txid46433[ORGN].xml',\n",
       " 'USH_Search_txid4837[ORGN].xml',\n",
       " 'USH_Search_txid4932[ORGN].xml',\n",
       " 'USH_Search_txid5011[ORGN].xml',\n",
       " 'USH_Search_txid505693[ORGN].xml',\n",
       " 'USH_Search_txid529818[ORGN].xml',\n",
       " 'USH_Search_txid55529[ORGN].xml',\n",
       " 'USH_Search_txid5691[ORGN].xml',\n",
       " 'USH_Search_txid5759[ORGN].xml',\n",
       " 'USH_Search_txid5762[ORGN].xml',\n",
       " 'USH_Search_txid5833[ORGN].xml',\n",
       " 'USH_Search_txid588596[ORGN].xml',\n",
       " 'USH_Search_txid5888[ORGN].xml',\n",
       " 'USH_Search_txid6035[ORGN].xml',\n",
       " 'USH_Search_txid60516[ORGN].xml',\n",
       " 'USH_Search_txid6087[ORGN].xml',\n",
       " 'USH_Search_txid61392[ORGN].xml',\n",
       " 'USH_Search_txid6185[ORGN].xml',\n",
       " 'USH_Search_txid6239[ORGN].xml',\n",
       " 'USH_Search_txid6334[ORGN].xml',\n",
       " 'USH_Search_txid6412[ORGN].xml',\n",
       " 'USH_Search_txid669202[ORGN].xml',\n",
       " 'USH_Search_txid691883[ORGN].xml',\n",
       " 'USH_Search_txid6945[ORGN].xml',\n",
       " 'USH_Search_txid72019[ORGN].xml',\n",
       " 'USH_Search_txid7227[ORGN].xml',\n",
       " 'USH_Search_txid73868[ORGN].xml',\n",
       " 'USH_Search_txid7574[ORGN].xml',\n",
       " 'USH_Search_txid7668[ORGN].xml',\n",
       " 'USH_Search_txid7719[ORGN].xml',\n",
       " 'USH_Search_txid79327[ORGN].xml',\n",
       " 'USH_Search_txid7955[ORGN].xml',\n",
       " 'USH_Search_txid81824[ORGN].xml',\n",
       " 'USH_Search_txid946362[ORGN].xml',\n",
       " 'USH_Search_txid9606[ORGN].xml']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_BLAST_XMLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_BLAST_XMLs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parse_and_summarize(list_of_BLAST_XMLs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
