{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Usher Syndrome associated genes and the evolution of sensory structures\n",
    "\n",
    "\n",
    "<img src =\"files/Presentation_fig1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the project at github:\n",
    "\n",
    "https://github.com/hspeck/project.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: BLAST sequences of Interest against NCBI Databases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_taxa_file_name=open(\"full_list_taxa_NCBI.txt\", \"r\")\n",
    "full_taxa_list = full_taxa_file_name.read()\n",
    "#read in the list of organisms to search\n",
    "formated_full_taxa_list = full_taxa_list.replace(\"a\", \"\").replace('\"', '').replace(\"\\n\", \"[ORGN]\\n\").replace(\":\", \"\").split(\"\\n\")\n",
    "#format the organism name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### qBLAST function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search_taxa_all_gene_delay(list_of_taxa):\n",
    "    #takes a list of taxa and will run blast for sequences contained in a file\n",
    "    #will loop through the list and run blast for each one\n",
    "    #will save each result to a separate xml file\n",
    "    from Bio.Blast import NCBIWWW\n",
    "        #imports the NCBIWWW module from Biopython\n",
    "    import time\n",
    "        #gives us the ability to delay our imputs to not spam the NCBI servers and get kicked off\n",
    "    \n",
    "    with open(\"USH_Search_seq.fasta\", \"r\") as fasta_file:\n",
    "        sequences = fasta_file.read()\n",
    "        fasta_file.close()\n",
    "        #reads in the file we will be searching\n",
    "        \n",
    "    for i in list_of_taxa:\n",
    "        result_handle = NCBIWWW.qblast(\"blastp\", \n",
    "                                       \"refseq_protein\", \n",
    "                                       sequences, \n",
    "                                       alignments=100, \n",
    "                                       descriptions=100, \n",
    "                                       expect=0.00001, \n",
    "                                       entrez_query=str(i))\n",
    "        file_name=str(\"USH_Search_\"+str(i)+\".xml\") #this creates a name for the file\n",
    "        save_file=open(file_name, \"w\")  #we are opening a file that does not yet exist to write to it\n",
    "        save_file.write(result_handle.read())  #writing the result of our blast search to local file\n",
    "        save_file.close() #closing it to allow the file to actually write it\n",
    "        result_handle.close() #close the results handle\n",
    "        print(\"created \"+ file_name)\n",
    "        time.sleep(60)  #this gives 1 minute between writing the output and sending another request to the ncbi server\n",
    "            #hopefully this will prevent spamming the server \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete the hashtag below to search!\n",
    "(be prepared to wait 5 hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#    search_taxa_all_gene_delay(formated_full_taxa_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Output XML files and summarize search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_and_getID(blast_output_xml):\n",
    "    #  goes through the output of a BLAST xml file \n",
    "    # finds the ID for the top 5 of the result\n",
    "    from Bio.Blast import NCBIXML\n",
    "    from Bio.SeqRecord import SeqRecord\n",
    "    #import the required libraries\n",
    "    \n",
    "    for taxa_id in blast_output_xml:\n",
    "        file_name = str(\"USH_Search_\"+taxa_id+\"[ORGN].xml\")\n",
    "        #this sets the handle, without having to format every single name of the input files\n",
    "        \n",
    "        result_handle = open(str(file_name), \"r\") #sets the result handle\n",
    "        blast_records = NCBIXML.parse(result_handle)\n",
    "        #need to use parse if it has multiple records in it\n",
    "        for blast_record in blast_records:\n",
    "            org_desig=file_name.split(\"_\")[2].split(\"[\")[0].replace(\" \", \"_\")\n",
    "            #properly formats the taxa id so we can use it to name things\n",
    "            \n",
    "            homo_sapiens = \"[Homo sapiens]\"\n",
    "            blast_query=blast_record.query\n",
    "            if homo_sapiens in blast_query:\n",
    "                gene_name=blast_record.query.split(\"|\")[4].split(\"[\")[0].replace(\" \", \"_\").replace(\"_protein\", \"\").replace(\"_isoform_b3\", \"\")\n",
    "                formated_gene_name = gene_name[1:-1]\n",
    "            else:\n",
    "                formated_gene_name=blast_query.split(\"|\")[4].split(\"_\")[0]\n",
    "            #this conditional properly formats the gene name so we can use it to name things\n",
    "                #Basically there are 2 formats of sequence names I used to do the search\n",
    "                #this statement switches the naming convention depending on which is used\n",
    "                #it's not very general, so in the future I will make sure to properly name my search sequences\n",
    "                #that should make this statement unnecessary \n",
    "            \n",
    "            \n",
    "            output_file_name=(\"gene_\"+formated_gene_name +\"_tiny_subset\"+ \"_summary.csv\")\n",
    "            #added subset here to see if we can limit the number of results to the top hits\n",
    "            output_file=open(output_file_name, \"a\")\n",
    "            \n",
    "            #this puts together a nicely named file for each gene and species\n",
    "            \n",
    "            alignment_file_contents=\"\"\n",
    "            #setting up an empty list to hold the output of the following loop\n",
    "            for alignment in blast_record.alignments[:3]:\n",
    "\n",
    "                score_counter=[]\n",
    "                e_val_counter=[]\n",
    "\n",
    "                for hsp in alignment.hsps:\n",
    "                    evalue=hsp.expect\n",
    "                    e_val_counter.append(evalue)\n",
    "                \n",
    "                seq_designation = alignment.title.split(\"|\")\n",
    "                gi_number = seq_designation[1]\n",
    "                ref_number = seq_designation[3]\n",
    "                annotation = seq_designation[4]\n",
    "                #breaking apart the annoation of the sequence name\n",
    "                #otherwise we'd have way too many delimiters within delimiters\n",
    "                output_line = str(gi_number + \",\"+ \n",
    "                                  ref_number + \",\" +\n",
    "                                  annotation+ \",\" +\n",
    "                                  str(min(e_val_counter)) + \"\\n\")\n",
    "                #this sets up the output for each alignment\n",
    "                #had to alter the line breaks and parenthesis positioning\n",
    "                \n",
    "                alignment_file_contents = alignment_file_contents + output_line\n",
    "                #this writes what we came up with to the holder string\n",
    "            output_file.write(alignment_file_contents)\n",
    "            #writing the output to the alignment file\n",
    "            output_file.close()\n",
    "        result_handle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reduced_subset_taxa_file = open(\"reduced_list_of_test_taxa.txt\", \"r\")\n",
    "reduced_subset_taxa = reduced_subset_taxa_file.read().splitlines()\n",
    "parse_and_getID(reduced_subset_taxa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example_contents = open(\"USH_Search_txid203908[ORGN].xml\",\"r\").read()\n",
    "#example_contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example_output = open(\"gene_WHRN_tiny_subset_summary.csv\").read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab Gene IDs from output with bash for each gene\n",
    "\n",
    "```\n",
    "cat gene_WHRN_tiny_subset_summary.csv | cut -d ',' -f 1 > WHRN_tiny_gi.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download full sequence for gene from NCBI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_seqs_from_list_and_autoname(in_filename):    \n",
    "    with open(in_filename, \"r\") as query_file:\n",
    "        query_ids = query_file.read().splitlines()\n",
    "    #open the file, grab the ids\n",
    "\n",
    "    from Bio import Entrez\n",
    "    Entrez.email = \"hspeck@ucla.edu\"\n",
    "    # import Bio Entrez, let NCBI know who I am\n",
    "\n",
    "    search_results = Entrez.read(Entrez.epost(db =\"protein\", \n",
    "                                              id = \",\".join(query_ids)))  # needs the id's to be as a list separated by commas\n",
    "    #upload the IDs to NCBI\n",
    "    webenv_return = search_results[\"WebEnv\"]\n",
    "    query_key_return = search_results[\"QueryKey\"]\n",
    "    #grab the relevant variables to call on the stuff we posted\n",
    "\n",
    "    count = len(query_ids)\n",
    "    #assigns the count based on the number of sequences we searched for\n",
    "\n",
    "    from urllib.error import HTTPError\n",
    "    # load required library for the try and except conditions\n",
    "\n",
    "    batch_size = 20\n",
    "    #this determines how many things we retrieve and write to the file\n",
    "    #can safely be larger in the future\n",
    "\n",
    "    out_filename = str(in_filename[:-7]+\".fasta\")\n",
    "    #attempting to rename the file based on the input of the original file\n",
    "    out_handle = open(out_filename, \"w\")\n",
    "    #open file to write to\n",
    "\n",
    "    for start in range(0, count, batch_size):\n",
    "        end = min(count, start+batch_size)\n",
    "        print(\"Going to download record %i to %i\" % (start+1, end))\n",
    "        attempt = 0\n",
    "        while attempt < 3:\n",
    "            attempt += 1\n",
    "            try:\n",
    "                fetch_handle = Entrez.efetch(db=\"protein\", #says which db\n",
    "                                             rettype=\"fasta\", #says what format the data should be in\n",
    "                                             retmode=\"text\", #what the output should be\n",
    "                                             retstart = start, #say what range of results you want returned\n",
    "                                             retmax = batch_size, #say end of range of results want returned\n",
    "                                             webenv = webenv_return, #specify the info we uploaded with ePost\n",
    "                                             query_key = query_key_return)\n",
    "            except HTTPError as err:\n",
    "                if 500 <= err.code <= 599:\n",
    "                    print(\"Recieved error from server %s\" % err)\n",
    "                    print(\"Attempt %i of 3\" % attempt)\n",
    "                    time.sleep\n",
    "                else:\n",
    "                    raise\n",
    "        data = fetch_handle.read()\n",
    "        fetch_handle.close()\n",
    "        out_handle.write(data)\n",
    "    out_handle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "download_seqs_from_list_and_autoname(\"WHRN_tiny_gi.txt\")\n",
    "#will give us the properly named input for the Multiple alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Alignment by MUSCLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Bio.Align.Applications import MuscleCommandline\n",
    "muscle_cline = MuscleCommandline(input = \"WHRN_tiny.fasta\", out = \"WHRN_tiny_Muscle_align.txt\")\n",
    "stdout, stder = muscle_cline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run through RAxML\n",
    "\n",
    "in shell\n",
    "```\n",
    "./raxmlHPC -m PROTGAMMAWAG -p 12345 -s Path/to/alignment/WHRN_tiny_Muscle_align.txt  -# 5 -n WHRNtn2\n",
    "```\n",
    "\n",
    "path depends on where RAxML is installed\n",
    "\n",
    "Note that number of runs was reduced in order to have the tree completed for the presentation\n",
    "\n",
    "We get a tree file out of this, feed it to R for the next part\n",
    "\n",
    "But first:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format the Sequence Names For Tree making\n",
    "\n",
    "\n",
    "Use Bash to grab the top lines of the Fasta lines\n",
    "\n",
    "```\n",
    "cat WHRN_tiny.fasta | grep \">\" > WHRN_tiny_annotations.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WHRN_annotations = open(\"WHRN_tiny_annotations.txt\", \"r\").readlines()\n",
    "name_file= open(\"WHRN_gene&sci&annotation.txt\", \"w\")\n",
    "for line in WHRN_annotations:\n",
    "    #this handles formating of names\n",
    "    #there are essentially a number of formats the genes can be name in, os it makes the naming process a bit tricky\n",
    "    \n",
    "    sequence_id = line.split(\" \")[0].replace(\">\", \"\")\n",
    "    #split the sequence ID out and get rid of FASTA formating\n",
    "    \n",
    "    \n",
    "    formated_org = line.split(\"[\")[1].split(' ')\n",
    "    genus_code = formated_org[0][:3]\n",
    "    genus = formated_org[0]\n",
    "    species_code = formated_org[1][:3]\n",
    "    final_org_name = genus_code + \"_\" + species_code\n",
    "    #splits out the genus and species\n",
    "    \n",
    "    taxa_group = taxa_Dict[final_org_name]\n",
    "    #assigns the species to a broad taxonomic division \n",
    "    \n",
    "    gene_annotation_slice = line.split(\"[\")[0].split(\" \")[1:]\n",
    "    if \"PREDICTED:\" in gene_annotation_slice:\n",
    "        if \"-like\" in gene_annotation_slice:\n",
    "            gene_annotation = gene_annotation_slice[0].replace(\" \", \"\")\n",
    "        else:\n",
    "            gene_annotation = gene_annotation_slice[1:3]\n",
    "    elif \"Drosophila\" in gene_annotation_slice:\n",
    "        gene_annotation = gene_annotation_slice[1:3]\n",
    "    else:\n",
    "        gene_annotation = gene_annotation_slice[0:1]\n",
    "    gene_annotation_final = \"_\".join(gene_annotation).replace(\",\", \"\")\n",
    "    #cuts down the gene annoatation names to make them more manageable\n",
    "    #problematic as the gene names do not conform to a single format that makes them easily parsable\n",
    "    #have to switch between formats\n",
    "    \n",
    "    combined_name = '\"' +final_org_name + \" \" + gene_annotation_final + '\"'\n",
    "    genus_and_gene = '\"' +genus + \" \" + gene_annotation_final + '\"'\n",
    "    \n",
    "    name_file.write(sequence_id+\",\"+\n",
    "                    final_org_name+\",\"+\n",
    "                    gene_annotation_final+\",\"+ \n",
    "                    taxa_group+ \",\"+ \n",
    "                    combined_name+ \",\" +\n",
    "                    genus_and_gene+'\\n')\n",
    "    #Writes it to the file\n",
    "    \n",
    "name_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Through R\n",
    "\n",
    "file at project/presentation_material/Presentation_R_file.R\n",
    "\n",
    "```\n",
    "rm(list = ls())\n",
    "library(ape)\n",
    "### Basic Tree!\n",
    "\n",
    "WHRN_tree <- read.tree(\"/Path/o/best/Tree/RAxML_bestTree.WHRNtn2\")\n",
    "plot(WHRN_tree)\n",
    "#bring in the tree from where ever it is and plot it\n",
    "\n",
    "```\n",
    "<img src = \"files/WHRN_basic_tree.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make it nice and readable\n",
    "\n",
    "```\n",
    "# Read in and format the annotation data\n",
    "WHRN_gene_annotations <- read.csv(\"WHRN_gene&sci&annotation.txt\", \n",
    "                                  header =FALSE, \n",
    "                                  stringsAsFactors = FALSE)\n",
    "names(WHRN_gene_annotations) <- c(\"GeneID\", \"OrgName\", \"Annotation\", \"Group\", \"CombinedName\", \"Genus_Gene\")\n",
    "rownames(WHRN_gene_annotations) <- WHRN_gene_annotations$GeneID\n",
    "\n",
    "\n",
    "\n",
    "# Reorder data frame to match rows\n",
    "\n",
    "order <- match(WHRN_tree$tip.label, rownames(WHRN_gene_annotations))\n",
    "WHRN_gene_annotations <- WHRN_gene_annotations[,][order,]\n",
    "\n",
    "\n",
    "WHRN_tree$tip.label <- WHRN_gene_annotations$Genus_Gene\n",
    "# Rename tips of Tree to increase Readability\n",
    "\n",
    "plot(WHRN_tree, cex = 0.5, label.offset = 0.1)\n",
    "# decrease size of labels a bit\n",
    "\n",
    "title(\"Whirlin (USH2D) best hits tree\")\n",
    "#add a title\n",
    "add.scale.bar()\n",
    "#add a scale bar!\n",
    "\n",
    "# Color the tips to indicate which lineage the organism belongs to\n",
    "\n",
    "WHRN_gene_annotations$Group <- as.factor(WHRN_gene_annotations$Group)\n",
    "\n",
    "#start by setting the Group to factor\n",
    "lineages <- unique(WHRN_gene_annotations$Group)\n",
    "cols <- rainbow(n = length(lineages))\n",
    "#color vector for legend\n",
    "colvec <- cols[WHRN_gene_annotations$Group]\n",
    "#color vector for tree\n",
    "tiplabels(pch = 19, col = colvec)\n",
    "\n",
    "\n",
    "# Add a legend!\n",
    "legend(x = \"bottomright\", lwd =0, pch = 19 , legend = levels(lineages), col = cols, cex = 0.7)\n",
    "```\n",
    "Here is the output:\n",
    "\n",
    "\n",
    "\n",
    "<img src =\"files/Whirlin_presentation_color_tree.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some clustering of predicted whirlins with Deuterostome whirlins, along with predicted but unannotated proteins\n",
    "\n",
    "However, not all predicted whirlins cluster note the Octopus predicted whirlin\n",
    "\n",
    "Annotated harmonin homologs clustering together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
